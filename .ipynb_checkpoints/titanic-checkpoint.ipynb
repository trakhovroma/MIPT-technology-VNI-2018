{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3293d6359d68e32c9d48c9da1f76c9facfa16996"
   },
   "source": [
    "> ## Homework 5: Trakhov Roman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# import packages:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb40577db1769b393ad2cca034477b7b63eca103"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3d99fc39ff5b4a6c989d311e79d8ba5eba4b85c9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f96d8842811a951e8f75467fdf76908cbd805ec6"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9532e54652ec54f3e50656a44614c6c6fd7b3acc"
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c246d015b750bb80fb771c15620c43c0189de186"
   },
   "outputs": [],
   "source": [
    "# left only important features (drop id's)\n",
    "train_df = train.drop(['PassengerId','Name','Ticket'], axis=1)\n",
    "test_df    = test.drop(['Name','Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ed9c1a8fdd6b7cc77ba7bc169e869d85382ee29"
   },
   "outputs": [],
   "source": [
    "# Embarked get dummies\n",
    "\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "#sns.factorplot('Embarked','Survived', data=train_df,size=4,aspect=3)\n",
    "\n",
    "fig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)\n",
    "# sns.factorplot('Survived',hue=\"Embarked\",data=titanic_df,kind='count',order=[1,0],ax=axis2)\n",
    "sns.countplot(x='Embarked', data=train_df, ax=axis1)\n",
    "sns.countplot(x='Survived', hue=\"Embarked\", data=train_df, order=[1,0], ax=axis2)\n",
    "\n",
    "embark_perc = train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\n",
    "sns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n",
    "\n",
    "embark_dummies_train  = pd.get_dummies(train_df['Embarked'].values)\n",
    "embark_dummies_test  = pd.get_dummies(test_df['Embarked'].values)\n",
    "\n",
    "cols = embark_dummies_train.columns\n",
    "train_df[cols] = embark_dummies_train\n",
    "test_df[cols]  = embark_dummies_test\n",
    "\n",
    "train_df.drop(['Embarked'], axis=1,inplace=True)\n",
    "test_df.drop(['Embarked'], axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06554328b4b7a7a868be5c2b04d93674cb78d1e8"
   },
   "outputs": [],
   "source": [
    "# Sex get dummies\n",
    "def get_person(x):\n",
    "    return 'child' if x.Age < 16 else x.Sex\n",
    "    \n",
    "train_df['Person'] = train_df.apply(get_person,axis=1)\n",
    "test_df['Person']    = test_df.apply(get_person,axis=1)\n",
    "\n",
    "# No need to use Sex column since we created Person column\n",
    "train_df.drop(['Sex'],axis=1,inplace=True)\n",
    "test_df.drop(['Sex'],axis=1,inplace = True)\n",
    "             \n",
    "person_dummies_titanic = pd.get_dummies(train_df['Person'].values)\n",
    "person_dummies_titanic.columns = ['Child','Female','Male']\n",
    "person_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "person_dummies_test  = pd.get_dummies(test_df['Person'].values)\n",
    "person_dummies_test.columns = ['Child','Female','Male']\n",
    "person_dummies_test.drop(['Male'], axis=1, inplace=True)\n",
    "\n",
    "cols = person_dummies_titanic.columns\n",
    "train_df[cols] = person_dummies_titanic\n",
    "test_df[cols]    = person_dummies_test\n",
    "\n",
    "fig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)\n",
    "sns.countplot(x='Person', data=train_df, ax=axis1)\n",
    "\n",
    "# average of survived for each Person(male, female, or child)\n",
    "person_perc = train_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\n",
    "sns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n",
    "\n",
    "train_df.drop(['Person'],axis=1,inplace=True)\n",
    "test_df.drop(['Person'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eaa5b7fee7a9a5bec4578d71b533cc385bea7301"
   },
   "outputs": [],
   "source": [
    "# Pclass get dummies\n",
    "pclass_dummies_titanic  = pd.get_dummies(train_df['Pclass'].values)\n",
    "pclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "pclass_dummies_test  = pd.get_dummies(test_df['Pclass'].values)\n",
    "pclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\n",
    "pclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n",
    "\n",
    "train_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "test_df.drop(['Pclass'],axis=1,inplace=True)\n",
    "\n",
    "cols = pclass_dummies_titanic.columns\n",
    "train_df[cols] = pclass_dummies_titanic\n",
    "test_df[cols] = pclass_dummies_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bad1cec6baad727f6b48bc872a3ee1afa0c29c51"
   },
   "outputs": [],
   "source": [
    "#Cabin: drop this feature because too much nans\n",
    "train_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "test_df.drop(\"Cabin\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "eced03c5869b9fa2dd2b4815ea2f299a165b9f49"
   },
   "outputs": [],
   "source": [
    "# impute nan to mean values\n",
    "train_df['Age'] = train_df['Age'].fillna(train_df[\"Age\"].mean())\n",
    "test_df['Age'] = test_df['Age'].fillna(train_df[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59c908f811844781fb621462ba5e506ea97a2f93"
   },
   "source": [
    "### Let's beging scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8888e3e6f5f4e412223aae623acd31e325d49ec5"
   },
   "outputs": [],
   "source": [
    "# some simle ensebble models + knn\n",
    "def get_ensemble_models():\n",
    "    rf = RandomForestClassifier(n_estimators=101,min_samples_leaf=3, min_samples_split=2)\n",
    "    bagg = BaggingClassifier(n_estimators=101,random_state=42)\n",
    "    extra = ExtraTreesClassifier(n_estimators=101,random_state=42)\n",
    "    ada = AdaBoostClassifier(n_estimators=101,random_state=42)\n",
    "    grad = GradientBoostingClassifier(n_estimators=101,random_state=42)\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=3)\n",
    "    knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "    #xgb = xgboost.XGBClassifier(n_estimators=101, random_state = 42)\n",
    "    classifier_list = [rf,bagg,extra,ada,grad, knn]\n",
    "    classifier_results = np.array([np.array([]),np.array([]),np.array([]),np.array([]),np.array([]), np.array([]),np.array([])])\n",
    "    classifier_targets = np.array([np.array([]),np.array([]),np.array([]),np.array([]),np.array([]), np.array([]),np.array([])])\n",
    "    classifier_name_list = np.array(['Random Forests','Bagging','Extra Trees','AdaBoost','Gradient Boost', 'knn'])\n",
    "    return classifier_list, classifier_name_list, classifier_results, classifier_targets\n",
    "def append_evaluation_metrics(trained_model, trained_model_name, X_test,y_test):\n",
    "    cr = [np.append(classifier_results[i], trained_model.predict(X_test)) if np.where(classifier_name_list == trained_model_name)[0][0] == i else classifier_results[i] for i in range(6)]\n",
    "    ct = [np.append(classifier_targets[i], y_test) if np.where(classifier_name_list == trained_model_name)[0][0] == i else classifier_targets[i] for i in range(6)]\n",
    "    return cr,ct\n",
    "def print_evaluation_metrics(trained_models,trained_model_names,classifier_results, classifier_targets):\n",
    "    for trained_model,trained_model_name,classifier_result, classifier_target in zip(trained_models, trained_model_names,classifier_results, classifier_targets):\n",
    "        print('--------- For Model : ', trained_model_name, ' ---------------\\n')\n",
    "        print(metrics.classification_report(classifier_target,classifier_result))\n",
    "        print(\"Accuracy Score : \",metrics.accuracy_score(classifier_target,classifier_result))\n",
    "        print(\"Roc_Auc Score : \",metrics.roc_auc_score(classifier_target,classifier_result))\n",
    "        print(\"---------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1a91567425a6f9d39f6a8d1ebbf423be3466e1e"
   },
   "outputs": [],
   "source": [
    "#create validate sample\n",
    "X_train,X_valid,y_train,y_valid = train_test_split(train_df.drop([\"Survived\"], axis = 1).values, train_df['Survived'].values, stratify =train_df['Survived'].values, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07dbc13684230b57dc16a8c7396cc6486d6b09d1"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "classifier_list, classifier_name_list, classifier_results, classifier_targets = get_ensemble_models()\n",
    "for classifier,classifier_name,classifier_result, classifier_target in tqdm(zip(classifier_list,classifier_name_list, classifier_results,classifier_targets)):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    classifier_results, classifier_targets = append_evaluation_metrics(classifier, classifier_name, X_valid, y_valid)\n",
    "print_evaluation_metrics(classifier_list,classifier_name_list,classifier_results, classifier_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec63645cb5c2e93127dd5668d2b2afb8913ac040"
   },
   "outputs": [],
   "source": [
    "#best score on validation set got EXtraTree model\n",
    "# train it on full data and score test sample:\n",
    "\n",
    "extra = ExtraTreesClassifier(n_estimators=101,random_state=42).fit(train_df.drop('Survived',axis = 1).values,train_df['Survived'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de3d5fcc02ff88e88f05ee98dd97a6ceb2fe5eae"
   },
   "outputs": [],
   "source": [
    "#score test sample\n",
    "prediction = extra.predict(test_df.dropna(axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1e01041750a0c3eeb1d3a115f961c23c6eede57"
   },
   "outputs": [],
   "source": [
    "# save submisson to csv\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": prediction\n",
    "    })\n",
    "submission.to_csv('titanic.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
