{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3293d6359d68e32c9d48c9da1f76c9facfa16996"},"cell_type":"markdown","source":"> ## Homework 5: Trakhov Roman"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# import packages:\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom tqdm import tqdm_notebook as tqdm\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb40577db1769b393ad2cca034477b7b63eca103"},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d99fc39ff5b4a6c989d311e79d8ba5eba4b85c9","scrolled":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f96d8842811a951e8f75467fdf76908cbd805ec6"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9532e54652ec54f3e50656a44614c6c6fd7b3acc"},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c246d015b750bb80fb771c15620c43c0189de186"},"cell_type":"code","source":"# left only important features (drop id's)\ntrain_df = train.drop(['PassengerId','Name','Ticket'], axis=1)\ntest_df    = test.drop(['Name','Ticket'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ed9c1a8fdd6b7cc77ba7bc169e869d85382ee29"},"cell_type":"code","source":"# Embarked get dummies\n\ntrain_df[\"Embarked\"] = train_df[\"Embarked\"].fillna(\"S\")\n\n#sns.factorplot('Embarked','Survived', data=train_df,size=4,aspect=3)\n\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n\n# sns.factorplot('Embarked',data=titanic_df,kind='count',order=['S','C','Q'],ax=axis1)\n# sns.factorplot('Survived',hue=\"Embarked\",data=titanic_df,kind='count',order=[1,0],ax=axis2)\nsns.countplot(x='Embarked', data=train_df, ax=axis1)\nsns.countplot(x='Survived', hue=\"Embarked\", data=train_df, order=[1,0], ax=axis2)\n\nembark_perc = train_df[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\nsns.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\n\nembark_dummies_train  = pd.get_dummies(train_df['Embarked'].values)\nembark_dummies_test  = pd.get_dummies(test_df['Embarked'].values)\n\ncols = embark_dummies_train.columns\ntrain_df[cols] = embark_dummies_train\ntest_df[cols]  = embark_dummies_test\n\ntrain_df.drop(['Embarked'], axis=1,inplace=True)\ntest_df.drop(['Embarked'], axis=1,inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"06554328b4b7a7a868be5c2b04d93674cb78d1e8"},"cell_type":"code","source":"# Sex get dummies\ndef get_person(x):\n    return 'child' if x.Age < 16 else x.Sex\n    \ntrain_df['Person'] = train_df.apply(get_person,axis=1)\ntest_df['Person']    = test_df.apply(get_person,axis=1)\n\n# No need to use Sex column since we created Person column\ntrain_df.drop(['Sex'],axis=1,inplace=True)\ntest_df.drop(['Sex'],axis=1,inplace = True)\n             \nperson_dummies_titanic = pd.get_dummies(train_df['Person'].values)\nperson_dummies_titanic.columns = ['Child','Female','Male']\nperson_dummies_titanic.drop(['Male'], axis=1, inplace=True)\n\nperson_dummies_test  = pd.get_dummies(test_df['Person'].values)\nperson_dummies_test.columns = ['Child','Female','Male']\nperson_dummies_test.drop(['Male'], axis=1, inplace=True)\n\ncols = person_dummies_titanic.columns\ntrain_df[cols] = person_dummies_titanic\ntest_df[cols]    = person_dummies_test\n\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\n\n# sns.factorplot('Person',data=titanic_df,kind='count',ax=axis1)\nsns.countplot(x='Person', data=train_df, ax=axis1)\n\n# average of survived for each Person(male, female, or child)\nperson_perc = train_df[[\"Person\", \"Survived\"]].groupby(['Person'],as_index=False).mean()\nsns.barplot(x='Person', y='Survived', data=person_perc, ax=axis2, order=['male','female','child'])\n\ntrain_df.drop(['Person'],axis=1,inplace=True)\ntest_df.drop(['Person'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaa5b7fee7a9a5bec4578d71b533cc385bea7301"},"cell_type":"code","source":"# Pclass get dummies\npclass_dummies_titanic  = pd.get_dummies(train_df['Pclass'].values)\npclass_dummies_titanic.columns = ['Class_1','Class_2','Class_3']\npclass_dummies_titanic.drop(['Class_3'], axis=1, inplace=True)\n\npclass_dummies_test  = pd.get_dummies(test_df['Pclass'].values)\npclass_dummies_test.columns = ['Class_1','Class_2','Class_3']\npclass_dummies_test.drop(['Class_3'], axis=1, inplace=True)\n\ntrain_df.drop(['Pclass'],axis=1,inplace=True)\ntest_df.drop(['Pclass'],axis=1,inplace=True)\n\ncols = pclass_dummies_titanic.columns\ntrain_df[cols] = pclass_dummies_titanic\ntest_df[cols] = pclass_dummies_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bad1cec6baad727f6b48bc872a3ee1afa0c29c51"},"cell_type":"code","source":"#Cabin: drop this feature because too much nans\ntrain_df.drop(\"Cabin\",axis=1,inplace=True)\ntest_df.drop(\"Cabin\",axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eced03c5869b9fa2dd2b4815ea2f299a165b9f49"},"cell_type":"code","source":"# impute nan to mean values\ntrain_df['Age'] = train_df['Age'].fillna(train_df[\"Age\"].mean())\ntest_df['Age'] = test_df['Age'].fillna(train_df[\"Age\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"59c908f811844781fb621462ba5e506ea97a2f93"},"cell_type":"markdown","source":"### Let's beging scoring"},{"metadata":{"trusted":true,"_uuid":"8888e3e6f5f4e412223aae623acd31e325d49ec5"},"cell_type":"code","source":"# some simle ensebble models + knn\ndef get_ensemble_models():\n    rf = RandomForestClassifier(n_estimators=101,min_samples_leaf=3, min_samples_split=2)\n    bagg = BaggingClassifier(n_estimators=101,random_state=42)\n    extra = ExtraTreesClassifier(n_estimators=101,random_state=42)\n    ada = AdaBoostClassifier(n_estimators=101,random_state=42)\n    grad = GradientBoostingClassifier(n_estimators=101,random_state=42)\n    mlp = MLPClassifier(hidden_layer_sizes=3)\n    knn = KNeighborsClassifier(n_neighbors=7, weights='distance')\n    #xgb = xgboost.XGBClassifier(n_estimators=101, random_state = 42)\n    classifier_list = [rf,bagg,extra,ada,grad, knn]\n    classifier_results = np.array([np.array([]),np.array([]),np.array([]),np.array([]),np.array([]), np.array([]),np.array([])])\n    classifier_targets = np.array([np.array([]),np.array([]),np.array([]),np.array([]),np.array([]), np.array([]),np.array([])])\n    classifier_name_list = np.array(['Random Forests','Bagging','Extra Trees','AdaBoost','Gradient Boost', 'knn'])\n    return classifier_list, classifier_name_list, classifier_results, classifier_targets\ndef append_evaluation_metrics(trained_model, trained_model_name, X_test,y_test):\n    cr = [np.append(classifier_results[i], trained_model.predict(X_test)) if np.where(classifier_name_list == trained_model_name)[0][0] == i else classifier_results[i] for i in range(6)]\n    ct = [np.append(classifier_targets[i], y_test) if np.where(classifier_name_list == trained_model_name)[0][0] == i else classifier_targets[i] for i in range(6)]\n    return cr,ct\ndef print_evaluation_metrics(trained_models,trained_model_names,classifier_results, classifier_targets):\n    for trained_model,trained_model_name,classifier_result, classifier_target in zip(trained_models, trained_model_names,classifier_results, classifier_targets):\n        print('--------- For Model : ', trained_model_name, ' ---------------\\n')\n        print(metrics.classification_report(classifier_target,classifier_result))\n        print(\"Accuracy Score : \",metrics.accuracy_score(classifier_target,classifier_result))\n        print(\"Roc_Auc Score : \",metrics.roc_auc_score(classifier_target,classifier_result))\n        print(\"---------------------------------------\\n\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1a91567425a6f9d39f6a8d1ebbf423be3466e1e"},"cell_type":"code","source":"#create validate sample\nX_train,X_valid,y_train,y_valid = train_test_split(train_df.drop([\"Survived\"], axis = 1).values, train_df['Survived'].values, stratify =train_df['Survived'].values, test_size = 0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"07dbc13684230b57dc16a8c7396cc6486d6b09d1"},"cell_type":"code","source":"%%time\nclassifier_list, classifier_name_list, classifier_results, classifier_targets = get_ensemble_models()\nfor classifier,classifier_name,classifier_result, classifier_target in tqdm(zip(classifier_list,classifier_name_list, classifier_results,classifier_targets)):\n    classifier.fit(X_train, y_train)\n    classifier_results, classifier_targets = append_evaluation_metrics(classifier, classifier_name, X_valid, y_valid)\nprint_evaluation_metrics(classifier_list,classifier_name_list,classifier_results, classifier_targets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec63645cb5c2e93127dd5668d2b2afb8913ac040"},"cell_type":"code","source":"#best score on validation set got EXtraTree model\n# train it on full data and score test sample:\n\nextra = ExtraTreesClassifier(n_estimators=101,random_state=42).fit(train_df.drop('Survived',axis = 1).values,train_df['Survived'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"de3d5fcc02ff88e88f05ee98dd97a6ceb2fe5eae"},"cell_type":"code","source":"#score test sample\nprediction = extra.predict(test_df.dropna(axis=1).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1e01041750a0c3eeb1d3a115f961c23c6eede57"},"cell_type":"code","source":"# save submisson to csv\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": prediction\n    })\nsubmission.to_csv('titanic.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}